# L0165 Vector Database Optimization Guide

## 1. How Keyword Matching Enhances Vector Search

Keyword matching addresses several key limitations of pure vector search:

### 1.1 Exact Term Precision
Vector embeddings capture semantic meaning but can miss exact terminology:
- **Query**: "Create a spreadsheet with cell A1"
- **Vector search alone**: Might return documents about "tables" or "grids" (semantically similar)
- **With keyword matching**: Ensures documents containing "A1" (exact cell reference) rank higher

### 1.2 Domain-Specific Terminology
In Graffiticode/L0165, specific syntax matters:
```javascript
// From the code - extracting cell references
const cellRefs = code.match(/\b[A-Z]{1,2}\d{1,3}\b/g);  // Matches A1, B12, AA3
```
- **Vector search**: Understands "cell reference" concept
- **Keyword matching**: Ensures exact cell names (A1, B12) match precisely
- **Combined**: Finds semantically relevant code that also uses the same cell references

### 1.3 Formula and Function Names
Looking at the feature extraction:
```javascript
// Detects formulas that start with '='
if (/text\s*:\s*"?=/.test(code) || /=\s*[A-Z]{1,2}\d+/.test(code)) tags.add("formula");
```
- **Query**: "sum formula in column B"
- **Vector search**: Finds addition/calculation concepts
- **Keyword matching**: Prioritizes documents with "sum" and "B" specifically

### 1.4 Handling Ambiguity
Vector embeddings can conflate similar concepts:
- **Query**: "border bottom"
- **Vector search**: Might return "border top", "border left" (all borders are similar vectors)
- **Keyword matching**: Ensures "bottom" specifically matches

### 1.5 Short Queries
Short queries have less context for embeddings:
- **Query**: "center text"
- **Vector search**: Limited semantic information
- **Keyword matching**: Direct match on "center" and "text" improves precision

### 1.6 The 70/30 Weight Balance
```javascript
const combinedScore = vectorScore * 0.7 + keywordScore * 0.3;
```
This weighting means:
- **70% semantic understanding**: Captures intent and meaning
- **30% exact matching**: Ensures specific terms aren't lost

### Real-World Example

Consider searching for: **"Create a table with formula =SUM(A1:A10) in cell B1"**

**Pure Vector Search might return:**
1. Document about creating tables (high semantic match)
2. Document about calculations (semantic match on SUM)
3. Document about spreadsheet layouts (general relevance)

**Hybrid Search would prioritize:**
1. Documents containing "SUM", "A1", "A10", "B1" (exact matches)
2. Documents with formulas starting with "=" 
3. Documents about table creation with those specific cells

### Benefits Captured in Analytics

The enhanced tracking now shows:
```javascript
// You can see which documents matched on keywords vs semantics
trackRetrieval(rid, documents.map(doc => ({
  similarity: doc.vectorScore,      // Semantic score
  keywordScore: doc.keywordScore,   // Exact match score
  combinedScore: doc.combinedScore, // Final ranking score
})))
```

This helps you:
- Identify when keyword matching saved a poor semantic match
- Tune the vectorWeight (currently 0.7) based on real performance
- See which specific terms (cell refs, formulas) drive successful matches

### When Keyword Matching is Most Valuable

1. **Technical documentation**: Function names, parameters, syntax
2. **Identifier matching**: Cell references (A1, B2), variable names
3. **Exact phrases**: "border bottom", "justify center"
4. **Version-specific**: Searching for "v: 0.2.1" finds exact version
5. **Short distinctive terms**: "assess", "method" in L0165 context

The hybrid approach ensures you get both the **conceptual understanding** from embeddings and the **precision** of exact term matching, making the search more robust for code generation tasks.

---

## 2. Corpus Searched for Keyword Matching

The keyword matching searches the **same documents** retrieved by vector search, but specifically examines the **embedding text** generated by `createEmbeddingText()`. This text corpus includes:

### 2.1 Language Identifier
- Format: `L0165` or similar
- Example: "L0165" for Graffiticode language

### 2.2 Original Prompts/Tasks
- The original user request or task description
- Example: `Prompt: Create a spreadsheet with formulas`

### 2.3 User Conversation Turns
- All user messages from training examples
- Extracted from `messages` array or `help` field
- Example: `User: Add a sum formula in cell B1`

### 2.4 Feature Tags Extracted from Code
**NOT the raw code itself**, but specific features:

- **L0165 Keywords**: `title`, `instructions`, `columns`, `cells`, `width`, `justify`, `border`, `format`, `assess`, `expected`, `method`, `text`

- **Cell References**: `A1`, `B12`, `AA3` (up to 25 references)

- **Formula Indicators**: Tagged as "formula" if code contains `=` patterns

- **Formatting Values**:
  - `center`, `right` (for justify)
  - `border bottom` 
  - `format [value]` (e.g., "format currency")

- **Version Tags**: Extracted from `v: "x.x.x"` patterns

### Important: What's NOT Searched

The keyword matching does **NOT** search:
- ❌ Raw code directly
- ❌ The actual Graffiticode syntax
- ❌ Comments within the code
- ❌ Variable names or function definitions

### Example Embedding Text

For a training example with:
```javascript
{
  lang: "0165",
  prompt: "Create a table with sum formula",
  code: "{ title: \"Sales\", cells: { A1: \"100\", B1: \"=SUM(A1:A10)\" }, border: \"bottom\" }",
  messages: [
    { role: "user", content: "Add totals row with sum" }
  ]
}
```

The embedding text would be:
```
"L0165. Prompt: Create a table with sum formula. User: Add totals row with sum. Features: title, cells, border bottom, A1, B1, formula"
```

### Why This Approach?

1. **Avoids code syntax confusion**: Doesn't match on syntactic elements like brackets, quotes
2. **Focuses on intent**: Matches the problem description and key features
3. **Efficient**: Smaller search space than full code
4. **Relevant**: Captures the most distinctive elements (cell refs, formulas, formatting)

### Keyword Matching Process

```javascript
// From query "Create table with formula in B1"
keywords = ["create", "table", "with", "formula"]  // (words > 3 chars)

// For each document, searches embedding text:
docText = "L0165. Prompt: Create a table with sum formula. Features: B1, formula"
// Matches: "create", "table", "formula" (3/4 = 75% keyword score)
```

---

## 3. How to Use L0165 Language Spec for Optimal Embedding Texts

### 3.1 Core L0165 Domain Vocabulary

Include these key terms that define L0165's purpose:
```javascript
// Current extraction from code
const keywordMatches = code.match(/\b(title|instructions|columns|cells|width|justify|border|format|assess|expected|method|text)\b/gi);
```

**Enhance your embedding texts with:**
- **Structural terms**: `spreadsheet`, `table`, `grid`, `worksheet`
- **Cell operations**: `cell`, `column`, `row`, `range`
- **Formulas**: `formula`, `calculation`, `sum`, `average`, `count`
- **Formatting**: `align`, `border`, `style`, `format`
- **Assessment**: `assess`, `validate`, `check`, `expected`

### 3.2 Structured Embedding Text Template

```javascript
function createOptimizedEmbeddingText(example) {
  const parts = [];
  
  // 1. Language identifier
  parts.push("L0165 spreadsheet");
  
  // 2. Primary intent/task
  parts.push(`Task: ${example.prompt}`);
  
  // 3. Key operations (what it does)
  const operations = extractOperations(example);
  if (operations.length) {
    parts.push(`Operations: ${operations.join(", ")}`);
  }
  
  // 4. Data structure (what it creates)
  const structure = extractStructure(example);
  if (structure) {
    parts.push(`Structure: ${structure}`);
  }
  
  // 5. Specific features used
  const features = extractL0165Features(example);
  if (features.length) {
    parts.push(`Features: ${features.join(", ")}`);
  }
  
  // 6. Cell references and ranges
  const cells = extractCellReferences(example);
  if (cells.length) {
    parts.push(`Cells: ${cells.join(", ")}`);
  }
  
  return parts.join(". ");
}
```

### 3.3 L0165-Specific Feature Extraction

```javascript
function extractL0165Features(example) {
  const features = new Set();
  const code = example.code || "";
  
  // Spreadsheet structure elements
  if (/\btitle\b/i.test(code)) features.add("has-title");
  if (/\binstructions\b/i.test(code)) features.add("has-instructions");
  if (/\bcolumns\b/i.test(code)) features.add("defines-columns");
  if (/\bcolumnHeaders\b/i.test(code)) features.add("column-headers");
  
  // Formula types
  if (/=SUM\(/i.test(code)) features.add("sum-formula");
  if (/=AVERAGE\(/i.test(code)) features.add("average-formula");
  if (/=COUNT\(/i.test(code)) features.add("count-formula");
  if (/=IF\(/i.test(code)) features.add("conditional-formula");
  if (/=[A-Z]\d+[\+\-\*\/]/i.test(code)) features.add("arithmetic-formula");
  
  // Cell formatting
  if (/format\s*:\s*["']currency["']/i.test(code)) features.add("currency-format");
  if (/format\s*:\s*["']percent["']/i.test(code)) features.add("percent-format");
  if (/format\s*:\s*["']date["']/i.test(code)) features.add("date-format");
  
  // Layout features
  if (/justify\s*:\s*["']center["']/i.test(code)) features.add("center-aligned");
  if (/justify\s*:\s*["']right["']/i.test(code)) features.add("right-aligned");
  if (/border\s*:\s*["']bottom["']/i.test(code)) features.add("bottom-border");
  if (/border\s*:\s*["']all["']/i.test(code)) features.add("all-borders");
  
  // Assessment features
  if (/\bassess\b/i.test(code)) features.add("has-assessment");
  if (/\bexpected\b/i.test(code)) features.add("has-expected-values");
  if (/\bmethod\b/i.test(code)) features.add("has-method");
  
  return Array.from(features);
}
```

### 3.4 Optimal Embedding Text Examples

**Example 1: Budget Spreadsheet**
```javascript
// Original prompt: "Create a monthly budget tracker"
// Code contains: cells with expenses, SUM formulas, currency formatting

// Optimal embedding text:
"L0165 spreadsheet. Task: Create a monthly budget tracker. Operations: track expenses, calculate totals, categorize spending. Structure: monthly budget table with categories and totals. Features: has-title, defines-columns, sum-formula, currency-format, bottom-border. Cells: A1, A2, A3, B1, B2, B3, C1"
```

**Example 2: Grade Calculator**
```javascript
// Original prompt: "Build a grade calculator with weighted averages"
// Code contains: assessment, expected values, percentage formulas

// Optimal embedding text:
"L0165 spreadsheet. Task: Build a grade calculator with weighted averages. Operations: calculate grades, apply weights, compute average. Structure: grade table with assignments and weights. Features: has-assessment, has-expected-values, average-formula, percent-format, conditional-formula. Cells: A1-A10, B1-B10, C1"
```

**Example 3: Simple Data Table**
```javascript
// Original prompt: "Make a contact list table"
// Code contains: title, columns, text cells

// Optimal embedding text:
"L0165 spreadsheet. Task: Make a contact list table. Operations: display contacts, organize data. Structure: contact table with name email phone columns. Features: has-title, defines-columns, column-headers, center-aligned. Cells: A1, B1, C1, A2-A10"
```

### 3.5 Best Practices for L0165 Embedding Texts

1. **Start with language context**: Always begin with "L0165 spreadsheet" to establish domain

2. **Use action verbs**: "calculate", "track", "display", "organize", "validate"

3. **Include structural hints**: "table", "grid", "rows", "columns", "cells"

4. **Specify formulas explicitly**: Name the formula type (sum, average, count) rather than just "formula"

5. **List actual cell references**: Include specific cells (A1, B2) and ranges (A1:A10)

6. **Add format context**: Mention currency, percent, date formats when relevant

7. **Include assessment terms**: If validation/checking is involved, use "assess", "validate", "check", "expected"

### 3.6 What to Avoid

```javascript
// BAD: Too generic
"Create a spreadsheet with data"

// BAD: Raw code syntax
"{ title: \"Budget\", cells: { A1: \"100\" } }"

// BAD: Missing L0165 context
"Task: Make a table"

// GOOD: Rich, searchable, domain-specific
"L0165 spreadsheet. Task: Create budget tracker. Operations: track income, expenses, calculate balance. Features: sum-formula, currency-format, has-title. Cells: A1-A12, B1-B12, C1"
```

### 3.7 Enhanced Feature Extraction for Your Database

Consider adding these to your `createEmbeddingText` function:

```javascript
// Range detection
if (/[A-Z]\d+:[A-Z]\d+/.test(code)) features.add("uses-ranges");

// Multi-column operations  
if (/columns\s*:\s*\[.*\]/i.test(code)) features.add("multi-column");

// Nested structures
if (/cells\s*:\s*\{[^}]*\{/.test(code)) features.add("nested-data");

// Mathematical operations
if (/multiply|divide|subtract|add/i.test(code)) features.add("math-operations");

// Data validation
if (/validate|check|verify/i.test(code)) features.add("data-validation");
```

---

## 4. Optimal Vector Database Size for L0165 Code Generation

### 4.1 Quality vs Quantity Trade-offs

Your system retrieves **3 examples** per query (default limit). This affects how many documents you need.

### 4.2 Recommended Database Sizes

#### Minimum Viable (100-200 documents)
- Covers core L0165 patterns
- Each pattern should have 2-3 variations
- Good for: Proof of concept, specialized use cases

#### Effective Coverage (500-1,000 documents)
- Multiple examples per feature combination
- Handles edge cases and variations
- Good for: Production with focused domain

#### Comprehensive (2,000-5,000 documents)
- Rich variety for each concept
- Complex combinations and edge cases
- Good for: General-purpose L0165 generation

#### Enterprise Scale (10,000+ documents)
- Extensive coverage of all possibilities
- Multiple difficulty levels per concept
- Good for: Large-scale production with diverse users

### 4.3 Coverage Analysis Framework

```javascript
// Estimate required documents based on L0165 features
const L0165_FEATURES = {
  // Core structures (need 10-20 examples each)
  structures: ['simple-table', 'multi-column', 'nested-data', 'with-headers'],
  
  // Formula types (need 15-25 examples each)
  formulas: ['SUM', 'AVERAGE', 'COUNT', 'IF', 'arithmetic', 'cell-references'],
  
  // Formatting options (need 5-10 examples each)
  formatting: ['currency', 'percent', 'date', 'text', 'number'],
  
  // Layout options (need 5-10 examples each)
  layout: ['left', 'center', 'right', 'borders', 'width'],
  
  // Special features (need 10-15 examples each)
  special: ['assessment', 'validation', 'instructions', 'complex-formulas']
};

// Calculate minimum coverage
function calculateMinimumDocuments() {
  const combinations = 
    4 * 6 * 5 * 5 * 4; // Basic combinations = 2,400
  
  const minExamplesPerPattern = 2; // At least 2 variations
  return combinations * minExamplesPerPattern; // ~4,800 for full coverage
}
```

### 4.4 Practical Recommendations by Use Case

#### For Focused L0165 Applications (300-500 documents)

```javascript
const FOCUSED_DISTRIBUTION = {
  'basic-tables': 50,           // Simple spreadsheets
  'formulas-basic': 80,         // SUM, COUNT, AVERAGE
  'formulas-advanced': 60,      // Complex calculations
  'formatting': 40,              // Currency, percent, etc.
  'cell-references': 70,        // A1, B2:B10 patterns
  'assessment-examples': 30,    // Validation/checking
  'edge-cases': 30,              // Error handling
  'combined-features': 40        // Multi-feature examples
};
// Total: 400 documents
```

#### For General L0165 Support (1,000-2,000 documents)

```javascript
const GENERAL_DISTRIBUTION = {
  // Core patterns (40%)
  'common-patterns': 400-800,
  
  // Variations (30%)
  'difficulty-levels': 300-600,  // Same task, different complexity
  
  // Edge cases (20%)
  'unusual-combinations': 200-400,
  
  // Negative examples (10%)
  'what-not-to-do': 100-200      // Help avoid common mistakes
};
```

### 4.5 Quality Metrics to Track

Monitor these metrics (now captured in your analytics) to determine if you need more documents:

```javascript
// From your enhanced analytics
const coverageMetrics = {
  // Retrieval quality
  avgSimilarityScore: 0.75,  // Target: > 0.7
  retrievalHitRate: 0.85,    // Target: > 0.8
  
  // Usage patterns
  documentsUsedRatio: 0.6,   // Used/Retrieved (Target: > 0.5)
  
  // Diversity
  uniqueDocumentsUsed: 150,  // How many different docs get used
  
  // Problem indicators (need more docs if):
  lowSimilarityQueries: [],   // Queries with similarity < 0.5
  noResultsQueries: [],       // Queries with no good matches
};
```

### 4.6 Optimal Distribution Strategy

```python
# Recommended distribution pyramid
DISTRIBUTION = {
  'high_frequency': {
    'count': '40% of database',
    'examples': 'Common tasks (basic tables, simple formulas)',
    'variations': '5-10 per pattern'
  },
  'medium_frequency': {
    'count': '35% of database',  
    'examples': 'Specific features (formatting, alignment)',
    'variations': '3-5 per pattern'
  },
  'low_frequency': {
    'count': '20% of database',
    'examples': 'Complex combinations, edge cases',
    'variations': '2-3 per pattern'
  },
  'negative_examples': {
    'count': '5% of database',
    'examples': 'Common errors, anti-patterns',
    'variations': '1-2 per pattern'
  }
}
```

### 4.7 Incremental Growth Strategy

Start smaller and grow based on analytics:

```javascript
// Phase 1: Core (200 docs)
const PHASE_1 = {
  goal: "Handle 60% of queries well",
  focus: "Most common L0165 patterns",
  metrics: "Track lowSimilarityQueries"
};

// Phase 2: Expand (500 docs)
const PHASE_2 = {
  goal: "Handle 80% of queries well",
  focus: "Add variations and edge cases",
  metrics: "Track which features need more examples"
};

// Phase 3: Refine (1000+ docs)
const PHASE_3 = {
  goal: "Handle 95% of queries well",
  focus: "Fill gaps identified by analytics",
  metrics: "Optimize based on actual usage"
};
```

### 4.8 Using Your Analytics to Decide

Your enhanced analytics now tracks:
- `embeddingText`: See what patterns are being searched
- `similarity`: Identify when scores are too low
- `documentsRetrieved` vs `documentsUsed`: See if retrieved docs are relevant

**Add more documents when:**
- Average similarity < 0.6
- Many queries retrieve < 3 relevant documents  
- Same documents keep getting retrieved (low diversity)
- Specific pattern queries consistently score low

### Bottom Line Recommendation

**Start with 500-800 high-quality documents** covering:
- 100 basic spreadsheet patterns
- 150 formula examples (all types)
- 100 formatting variations
- 100 cell reference patterns
- 50 assessment/validation examples
- 100-300 combined feature examples

Then use your analytics to identify gaps and grow to 1,500-2,000 as needed. Beyond 5,000 documents, you'll see diminishing returns unless you're handling very diverse use cases.

**Quality > Quantity**: 500 well-crafted, diverse examples will outperform 5,000 redundant ones.

---

## Summary

By leveraging these insights:

1. **Hybrid search** (70% vector, 30% keyword) provides optimal balance between semantic understanding and precision
2. **Embedding texts** should focus on intent, features, and domain vocabulary rather than raw code syntax
3. **500-800 high-quality documents** provide effective coverage for most L0165 use cases
4. **Analytics tracking** helps identify gaps and optimize the database over time

The key to success is creating rich, searchable embedding texts that describe what the L0165 code does and what features it uses, not the syntax itself. This makes your vector database much more effective at finding relevant examples for code generation.